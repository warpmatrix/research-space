# AlpaServe: Statistical Multiplexing with Model Parallelism for Deep Learning Serving

本篇文章面向模型并行这一个概念，进行了深入的探讨。

- model parallelism 主要用于将大模型部署于有限内存的设备上
- 并且随着大模型的兴起，推理系统上部署的模型愈发变大并且也产生了更多的（大）模型变种
- 基于数据并行直接对请求数量进行划分，会导致需要模型多个副本增大内存的开销
- 此前 model parallelism 的研究主要面向**吞吐量**开展，较少从**推理时延**的角度进行探讨

本文研究模型并行的方法，提出了 AlpaServe 确定推理服务中的放置和并行策略

- 通过模型并行的方法对同一个模型划分和放置，可以使不同 gpu 的协同工作，提高 gpu 资源的利用效率
  - 现有的推理系统往往将一个模型放置在一块专用的 GPU 上
- 即使增加了潜在的通信开销（10%），但是提高硬件的使用效率可以显著增加系统吞吐量

相关背景：

- 将模型的大量参数换入加速器的内存需要消耗数秒
- 为了响应用户请求的 SLO，目前主要的推理系统提供了 over-provision 的计算资源
- 目前很多模型都是基于一个 pre-train model 进行微调得到，一些模型可能存在一些共享的参数

模型并行的适用情况：

- 单卡内存较小的情况下，无法存放多种模型，造成潜在的 GPU 计算资源浪费
  - 单卡内存较大的情况下，单张 GPU 可以容纳多种模型，多张 GPU 的计算资源都可以得到充分利用，模型并行与副本 (replication) 没有明显差异
- 用户请求更密集的情况下，模型并行可以更好的利用 GPU 计算资源，提高系统的吞吐量

模型并行的主要难点：如何对模型进行划分和放置

- 模型划分存在多种影响因素，特别是单张 GPU 卡的内存
- 并且不同的并行方式 (inter/intra-parallelism) 也产生了不同的影响
  
不同的并行方式：

- intra-operator parallelism: 将单个算子在多台设备上进行划分
  - 需要进行 GPU 间的通信，完成输入输出的划分和聚合
  - 可以增加计算资源和内存的利用率，减少单个算子的执行时延
- inter-operator parallelism: 将模型执行图中不同的算子指派到不同的设备上
  - GPU 之间的通信发生在不同的 stage 之间，期间涉及的通信仅在两个设备之间发生，通信开销较小
  - 无法减少算子执行时间，并且略微增加了阶段之间的通信开销，算子的端到端延迟会略微增加
  - 但算子的端到端时延可以被流水线的并行执行所掩盖

模型并行的开销：

- 通信开销：不同设备进行中间结果传输导致的开销
  - intra-op parallelism 的开销仅由通信开销带来，并且每一阶段的通信开销无法通过流水线进行掩盖
- 不公平划分开销：由于设备差异、模型划分差异导致的开销
  - inter-op parallelism 中的执行效率由最慢的 stage 决定，占据了开销的主要部分
