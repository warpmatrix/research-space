# ECO: Edge-Cloud Optimization of 5G applications

2021 IEEE/ACM 21st International Symposium on Cluster, Cloud and Internet Computing (CCGrid)

和云计算的对比：云计算的延迟在 100ms 的量级，而边缘计算的延迟在十几毫秒到亚毫秒的量级

- 在人机交互的情况下，边缘计算才能达到人类没有感知差别的程度
- 在机器和机器通信的情况下，为了提升性能可以进一步缩小延迟

云边协同使用多层架构，由云、计算资源和存储资源组成

- 适用于工业 4.0、增强现实、虚拟现实等实时计算的场景

云边协同的优势：

- 可以满足高速率，低延迟，高吞吐量的应用需求
- 通过扩展更多边缘数据中心，可以实现更快的软件开发、部署、管理
- 云数据中心可以集中资源处理需要全局信息的函数执行

云边协同的挑战：

- 边缘计算需要在动态、地域稀疏、设备复杂（设备异构）的情景下进行计算
- 边缘设备的资源往往十分有限，设备之间进行通讯往往成本过高
- 边缘设备需要处理网络中断等容错问题，需要新的技术解决

视频分析的一些特点：带宽敏感应用、延迟敏感应用

实验和系统的相关设置:

- 系统的延迟由两部分组成：计算延迟（节点时延）和传输延迟（边的时延）
  - 计算可以在本地或者云端进行，各自对应两种计算的方式
  - 传输时延分成两个部分：上传时延和下载时延
- 系统的成本主要为计算成本：边缘的计算成本、云端的计算成本
- 系统目的为达到延迟要求的情况下，成本尽可能低
  - 一般而言，越接近本地，延迟越低计算成本越高
  - 对于多层的计算环境下，系统逐层进行考虑？
  - 自边缘向云端进行考虑，保证时延得到满足
- 系统求解算法：最小割算法（最多包含一条分割？按道理应该不止）
  - 每层之间使用类似贪心的算法进行分割？可能无法达到最优解
  - 除非他的时延要求针对每一个微服务但显然不合理

系统的组成部分：Policy Engine, Scheduler

- Policy Engine (PE)：制定系统调度的策略
- Scheduler (S)：具体确定如何执行系统的策略（static、dynamical）、微服务的放置位置

实验结果：

- 实验环境的设置：关键路径的条数、涉及的数据库数量、实验的网络环境（LAN, edge-only, cloud-only, hybrid）
- edge 和 device 之间的传输速率 $\gg$ cloud 和 device 之间的传输速率
- 但 latency 并没有想象中以数量级为单位的那种差距
- 和直接全部数据上传到云的静态 mapping 相比，可以获得更小的时延
- 动态 mapping 可以获得无缝的服务，避免由于网络波动造成的影响
- 同时也可以获得更小的成本代价

论文的主要特点：

- 讨论微服务组成 pipeline 的组织方式
- 同时讨论如何动态组织微服务
